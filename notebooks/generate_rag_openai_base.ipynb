{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to replicate the following blog code:\n",
    "\n",
    "https://aws.amazon.com/fr/blogs/machine-learning/generate-synthetic-data-for-evaluating-rag-systems-using-amazon-bedrock/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "    Here is some context:\n",
    "    <context>\n",
    "    {}\n",
    "    </context>\n",
    "\n",
    "    Your task is to generate 5 questions in FRENCH that can be answered using the provided context and return a JSON object of a list of questions, following these rules:\n",
    "\n",
    "    <rules>\n",
    "    1. The question should make sense to humans even when read without the given context.\n",
    "    2. The question should be fully answered from the given context.\n",
    "    3. The question should be framed from a part of context that contains important information. It can also be from tables, code, etc.\n",
    "    4. The answer to the question should not contain any links.\n",
    "    5. The question should be of moderate difficulty.\n",
    "    6. The question must be reasonable and must be understood and responded by humans.\n",
    "    7. Do not use phrases like 'provided context', etc. in the question.\n",
    "    8. Avoid framing questions using the word \"and\" that can be decomposed into more than one question.\n",
    "    9. The question should not contain more than 10 words, make use of abbreviations wherever possible.\n",
    "    </rules>\n",
    "\n",
    "    To generate the question, first identify the most important or relevant part of the context. Then frame a question around that part that satisfies all the rules above.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "Ces premiers ouvrages donnèrent naissance à des compilations, à des\n",
    "abrégés plus ou moins médiocres qui n'apprenoient rien de nouveau. Une\n",
    "dispute qui s'éleva quelques années après, entre deux savants[3], sur\n",
    "nos anciennes églises, sans éclaircir beaucoup la question qu'ils\n",
    "traitoient, répandit quelques nouvelles lumières sur les antiquités de\n",
    "Paris. Pendant ce temps, Henri Sauval, avocat au parlement,\n",
    "travailloit à nous donner des connoissances plus exactes et plus\n",
    "étendues sur un sujet aussi important. Il recueillit, dans les dépôts\n",
    "publics et dans les archives particulières, une quantité prodigieuse\n",
    "de documents et de titres sur l'état ancien et moderne de la ville de\n",
    "Paris, les lut, les dépouilla avec une patience infatigable; mais\n",
    "n'eut ni le temps ni peut-être le talent de les mettre en ordre, de\n",
    "les comparer, de les vérifier. Il en est résulté que son immense\n",
    "recueil n'est qu'un amas informe de matériaux confondus ensemble, et\n",
    "dont il est impossible d'user sans y apporter les plus grandes\n",
    "précautions. Il est plein de répétitions, de détails fatigants, de\n",
    "trivialités, inexact dans les faits, peu judicieux dans les\n",
    "réflexions; et ses erreurs sur une foule de matières, principalement\n",
    "sur l'appréciation des monuments, sont telles, qu'elles seroient\n",
    "insupportables aujourd'hui aux personnes même les moins éclairées.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\")  # This is the default and can be omitted\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt_template.format(context),\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'questions': ['Qui a travaillé sur les antiquités de Paris?', 'Quels problèmes rencontraient les travaux de Sauval?', 'Quel type de documents a recueilli Henri Sauval?', 'Quel est le défaut majeur du recueil de Sauval?', 'Comment étaient les erreurs de Sauval sur les monuments?']}\n"
     ]
    }
   ],
   "source": [
    "questions_json_object = json.loads(chat_completion.choices[0].message.content)\n",
    "print(questions_json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_template = \"\"\"\n",
    "    It is your task to generate an answer to the following questions <questions>{}</questions> only based on the <context>{}</context></task>\n",
    "    The output should be only the answer generated from the context.\n",
    "    <rules>\n",
    "    1. Only use the given context as a source for generating the answer.\n",
    "    2. Be as precise as possible with answering the question.\n",
    "    3. Be concise in answering the question and only answer the question at hand rather than adding extra information.\n",
    "    </rules>\n",
    "    Only output the generated answer as a sentence. No extra characters.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\")  # This is the default and can be omitted\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": generation_template.format(\n",
    "                context, questions_json_object[\"questions\"][0]\n",
    "            ),\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o-mini\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Henri Sauval a travaillé sur les antiquités de Paris.'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-bench-aMooNfa2-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
